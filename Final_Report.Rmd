---
title: "Final_Report"
author: "Haolin Zhong, Shaocong Zhang, Yuxuan Wang, Boqian Li"
date: "12/7/2021"
output: 
  html_document:
    code_folding: hide
---

&nbsp;

# Motivation

The progress of computer and Internet technology has promoted the development of society. In terms of entertainment, the vibrant film industry is now facing another revolution with the Internet and big data support. How to accurately recommend information to users that match their preferences has become an important application and a major challenge in the field of data science. In this way, many websites have established complex, reliable and highly accurate film preference recommendation algorithms or systems. These algorithms or systems are great inventions, which can effectively meet the users' need to watch movies and greatly reduce the time required for users to search movies. In this context, we want to try to make a demo movie recommendation system based on [movielens](https://grouplens.org/datasets/movielens/latest/) dataset and try to apply the recommendation system used in daily life to our own website.


&nbsp;

# Related work

Haolin has previous exposure to the movielens dataset in his studies and has had some ideas about it. Shaocong, Yuxuan and Boqian all have some good knowledge of statistics, and are good at data analysis with R. At the same time, all of us hope to learn something new and complete the challenge through this project. We are eager to improve ourselves and with this thought in mind, we decide to complete this difficult project.

&nbsp;

# Initial questions
- Which movies have the highest ratings? 
- Are there any significant differences in ratings of movies in different categories? (Which types of movies do people like)
- Is there any relationship between movie ratings and movie release year? (Have movie ratings worsened in recent years？)
- Is there any relationship between movie ratings and review time? (Is it harder and harder to cater to the tastes of the audience？)
- What kind of movies should be provided to new users?
- How do we recommend movies to the users that alreday in our dataset?

&nbsp;

# Data

### Source
Dataset source used for EDA analysis:[MoiveLensdataset](https://grouplens.org/datasets/movielens/latest/)
- MovieLens, a movie recommendation service, provided this dataset (ml-latest-small), which describes 5-star rating and free-text tagging activities. Over 9742 movies, it has 100836 ratings and 3683 tag applications. Between March 29, 1996, and September 24, 2018, 610 people produced this data. On September 26, 2018, this dataset was created.
- The participants were chosen at random. All of the individuals that were chosen had rated at least 20 films. There is no demographic information provided. An id is assigned to each user, and no additional information is supplied.
- The files links.csv, movies.csv, ratings.csv, and tags.csv contain the data. 

&nbsp;

### Data Cleaning



&nbsp;

# Exploratory analysis


&nbsp;

## Summaries

### Overview of dataset "ratings.csv"

We applied the "summarise()" function to briefly describe the variable "rating". According to the result, variable rating show that the minimum is 0.5, the first quantile is 3, median is 3.5, mean is 3.502, third quantile is 4 and the maximum is 5.Since userid, movieid, timestamp only represent the ID of users, id of movies respectively, and digital record of the time of occurrence of a particular movie, we choose not to analyze those three variables.

&nbsp;

### Overview of dataset "movies.csv"

We count the 5 most appeared genres and made a table. The result are as following. Drama appeared 4361 times,1st place. Comedy appeared 3756 times, 2nd place. Thriller appeared 1894 times, 3rd place. Action appeared 1828 times, 4th place.Romance appeared 1596 time, 5 th place. Next, we also count the 5 most appeared year of the movie released, and made a table which shoes the result. 2006 appeared 733 times,1st place. 2009 appeared 719 times, 2nd place. 2005 appeared 709 times, 3rd place. 2002 appeared 705 times, 4th place. 2008 appeared 691 time, 5 th place.




&nbsp;

## Exploratory Statistical Analyses


### Find popular movies and high-rating movies

 In order to find the top 5 popular movies with highest rating, we filtered movies with rating less than 5, and count the 5 most rated movies. The Shawshank Redemption (1994) is the most popular movie, which has 153 times user rating. No.2 Pulp Fiction (1994),  has 123 times user rating. 116 times user rating, Forrest Gump (1994) wins the 3rd popular place. The Matrix (1999) has 109 times user rating,and is the fourth place among the top 5 popular movies. No. 5 is Star Wars: Episode IV - A New Hope (1977), and it has 104 times user rating. We also find out that among those 5 most rated movies and highest rating movies, genres with tag drama appears the most(3 times, appear in Forrest Gump (1994), Pulp Fiction (1994),The Shawshank Redemption (1994)). We also find out one interesting fact is that among the 5 most popular movies and 5 highest rating movies, 3 movies are released in 1994; 4 movies are released in the 90s.



&nbsp;

### Find  the average rating of each genres in different year

As to find out the average rating of each genres in different year, we first seperrate the combined genre and find out the average rating in different by using groupby and summarize functions. The table clearly shows that in 1902, the average ratings for genres Action, Adventure, Fantasy, Sci-Fi are all 3.5. In 1903, the average ratings for genres Crime and Western are both 2.5. The averages for genres Animation, Comedy, Sci-Fi in 1908 are all 4.0. The genre Drama's average ratings in 1915 is 2.0.



&nbsp;

### Kruskal-Wallis Test regarding user ID and rating

We first wanted to do a test to determine whether there are any statistically significant differences between the mean ratings of the user from the 600 users are different by using ANOVA.In order to use ANOVA, we checked whether the rating is normally distributed. However, because the plot showed that the rating is not normally distributed, we need to use non parametric test.Thus, we used the Kruskal-Wallis Test regarding user ID and rating. The Kruskal-Wallis H test (also known as the "one-way ANOVA on ranks") is a rank-based nonparametric test that may be used to see if two or more groups of an independent variable on a continuous or ordinal dependent variable have statistically significant differences. It is the nonparametric counterpart of the one-way ANOVA (Kruskal-Wallis H Test in SPSS Statistics | Procedure, output and interpretation of the output using a relevant example., 2021). Our assumption for KW test are: $H_0:\mu_{0}=\mu_1=\mu_2=\mu_3=...=\mu _x$,$H_1: \text{At least two of the mean ratings of the users are different}$. The result shows that the p value is less than 0.05.We can thus conclude that at 0.05 significance level, we reject the null hypothesis and conclude that at least two of the mean ratings of the user from the 600 users are different.




&nbsp;

## Visualizations

### Rating distribution among different genres

In order to find the rating distribution among different genres, we decided to use boxplot .The boxplot regarding ratings and genres shows that the spread of the ratings of War, Mystery,Horror and Crime are larger comparing to the other ratings of genres. All of ratings have outliers around either 1.0 point or 0.5 point. The ratings of genres Film-Noir and documentary have outliers at 1.5 points.We can also conclude that the mean of the ratings of genres like Thriller,sci-fi, Romance, Musical, Horror, Fantasy, Comedy, Children, Adventure and Action all equal to 3.5. The mean of the ratings of genres include Western, War, Mystery, IMAX, Film-Noir, Drama, Documentary, Crime and Animation all equal to 4. 



&nbsp;

### Rating distribution among different years

Next up, we also decided to use boxplot to show the rating distribution among different years.
Since this dataset include too much year, we choose to show only part of the boxplot regarding year and rating.According to the boxplot, we can conclude that the rating of years including 2010, 2009, 2007,2006 and 1998 have the least rating data records. There is no obivous trend shown in the plot.







&nbsp;

# Additional analysis

### Identification of differentiable movies

We implemented adaptive bootstrapping algorithm [(Golbandi, N., et al. 2011)](https://dl.acm.org/doi/10.1145/1935826.1935910) to find movies significantly differentiate people of different taste. 

&nbsp;

According to user’s response to the given movie, the algorithm classifies users into three sub-groups: lovers $N^{+}$, haters $N^{-}$, and people unknown of the movie $\overline{N}$. We choose 3.5 as the cut-off to determine whether users are lovers or haters, as our exploratory analysis found that 3.5 is the median of all ratings. 

&nbsp;

The algorithm defined a term $D_{m}$, which is equal to the sum of subgroups’ standard deviation of ratings on other movies ($\space D(m) = \sigma_{u \in N^{+}(m)} + \sigma_{u \in N^{-}(m)} + \sigma_{u \in \overline{N}(m)} \space$), to measure movies’ differentiation ability. By the definition, the most differential movie, i.e. the best splitter, should have the lowest $D_{m}$, because bad splitters will divide people with different taste into the same sub-group, resulting in increased $D_{m}$. 

&nbsp;

Once the algorithm found the most differential movie for overall users, it will repeat the above process in the 3 sub-groups, Lovers, haters and people unknown of this movie, separately. This recursive process was thus named bootstrapping. Subsequently, the algorithm will build a structure similar to a decision tree whose nodes are movies. Our implementation constructed such a ternary tree structure with a depth of 3. The result can be interpreted by the figure below:


<img src="pics/recsys.png" style="width:80%">

&nbsp;

For new users, let them rate on “The Last Samurai” at first. Users who give ratings above or equal to 3.5 are considered to be lovers, and those who give ratings below 3.5 are considered to be haters. Users can also reply that they haven’t watched this movie. For lovers, we then let them rate on “The Lord of the Rings: The Two Towers”, for haters we let them rate on “Finding Nemo”, and the unknown will be asked to rate on “City of God”. After rating on the second provided movie, users will then be asked to rate on the third movie which is also adaptively provided. 

&nbsp;

Since these movies significantly differentiate people of different taste, collection of user’s rating on them will allow us to generate more personalized recommendation.


&nbsp;

### User-similarity-based recommendation

A basic strategy for recommendation is, find users similar to the new user, and recommend the new user with what similar users like. Based on this strategy, a technique, collaborative filtering, was invented to making predictions (filtering) about the interests of a user by collecting preferences or taste information from many similar users (collaborating).

&nbsp;

This algorithm predict ratings with the following procedures:
-	Find X most similar users to the given user (Here we set X to 10)
-	Find all movies that these similar users have rated and the given user has not watched
-	Predict the given user’s ratings on these movies based on the similarity measure and ratings of similar users. The formula is:

$$
\hat{r}_{u m}=\bar{r}_{u}+\frac{\sum_{v \in S(u, K) \cap N(m)} w_{u v}\left(r_{v m}-\bar{r}_{v}\right)}{\sum_{v \in S(u, K) \cap N(m)}\left|w_{u v}\right|}
$$

In the above process, finding similar users and predicting ratings involve the measurement of similarity, $w_{uv}$. We considered two measurements, cosine similarity and Pearson correlation, and compared their performance through experimentation.

$$
\begin{align}
& \text{Cosine Similarity}: & w_{u v} = \frac{\sum_{m \in M} r_{u m} \cdot r_{v m}}{\sqrt{\sum_{m \in M}r_{u m}^{2} \cdot \sum_{m \in M}r_{v m}^{2}}}
\\
\\
& \text{Pearson Correlation}: & w_{u v} =\frac{ \sum_{m \in M}\left(r_{u m}-\bar{r}_{u}\right) \cdot\left(r_{v m}-\bar{r}_{v}\right)}{\sqrt{\sum_{m \in M}\left(r_{u m}-\bar{r}_{u}\right)^{2} \sum_{m \in M}\left(r_{v m}-\bar{r}_{v}\right)^{2}}}
\end{align}
$$

We performed 30 rounds of experiment. In each round, for each user, we randomly extract 20% records of their ratings as the test dataset, and the remained dataset as train dataset. Then, we use the two similarity measures separately to find similar users and subsequent predicted ratings on corresponding movies in the test dataset. Finally, we compute the RMSE between predicted ratings and actual ratings in the test data set, and get the two RMSE values.

&nbsp;

The [comparison between RMSE values](https://shaocongz.github.io/Final_Project/user_similarity.html#Compare_RMSE) of predictions based on the two measurement revealed that in this dataset, Pearson correlation is a better measurement which leads to smaller prediction error. Therefore, we implemented the algorithm with Pearson correlation in our shiny app.

&nbsp;

### Latent-factor-based recommendation

we built a latent factor model based on Funk-SVD to predict ratings for existing users in the dataset.

&nbsp;

Funk-SVD was named and authored by [Simon Funk](https://sifter.org/~simon/journal/20061211.html). The core idea of this algorithm is that decompose the user-movie sparse matrix $R$ into two matrix, the user feature matrix $P$ and the movie feature matrix $Q$ which satisfies $R = P \times Q^T$, then predicted rating by calculating $\displaystyle R_{um} = P_u \cdot Q^T_m$. Features are latent factors that we can't and don't have to directly measure or understand. 

&nbsp;

In human words, the interaction between a user's latent characteristics and a movie's latent characteristics decides the user's rating to the movie. Find values of these latent characteristics by decomposing the rating matrix, then predict ratings based on them.

&nbsp;

We implemented this algorithm and predicted ratings on the matrix constructed from the first 20 users and the first 20 movies in the dataset. To find $P$, $Q$, we generated two random matrix, and performed gradient descent to minimize the loss to let their product approximate the true rating matrix.

&nbsp;

In gradient descent, the loss function was defined as:

$$\displaystyle L(P, Q) = \sum_{(u, m) \in \text{Train}} \left(R_{um} - P_u \cdot Q^T_m \right)^2  + \lambda \sum_u||P_u||^2 + \lambda \sum_m ||Q_m||^2$$

By performing differentiation, we found the partial derivatives of loss to $P$ and to $Q$:

$$\frac {\partial}{\partial P_u}L = \sum_{m} 2(P_uQ_m^T - R_{um})Q_m + 2\lambda P_u \\ \frac {\partial}{\partial Q_m}L = \sum_{u} 2(P_uQ_m^T - R_{um})P_u + 2\lambda Q_m$$ 

Accordingly, we can update the value of $P$ and $Q$ in each round of gradient descent:

$$P_u := P_u - \alpha \frac {\partial L}{\partial P_u} \\ Q_m := Q_m - \alpha \frac {\partial L}{\partial Q_m}$$

Our train process on the train data [minimized the loss to approximately 0](https://shaocongz.github.io/Final_Project/SVD.html#Train). We further applied this
model to [predict ratings for NA value in the original rating matrix](https://shaocongz.github.io/Final_Project/SVD.html#Predict__Visualization). With the size of the matrix in the train data enlarges, the time cost for training this model accurately increases. Therefore, we didn't apply this model in our
shiny app or try to optimize this model.

&nbsp;

### Tag-based recommendation

In this project, we have implemented several algorithms for recommendation systems, such as tree-based bootstraping, user-similarity based recommendation, and tree-based bootstrapping. The next one I want to introduce is the tag-based recommendation system algorithm. Before introducing the new recommendation system, we need a new dataset to carry on the thoughts. The "tag.csv" in the Movielens contains the data we are looking for. The dataset includes user id, movie id, tag and time stamp (it represents seconds since midnight Coordinated Universal Time of January 1, 1970, but we will not use this variable in this part). Based on these information, we can construct a personalized recommendation algorithm by:

1. Count the most commonly used tags of the user.

2. For each tag, count the movies that have been labeled the most times.

3. For a user, first find his commonly used tags, and then find the most popular movies with these tags to recommend to the user.

For the above algorithm, the formula of user u's interest in movie i is as follows:

$p(u, i)=\sum_{b} \frac{n_{u, b}}{\log \left(1+n_{b}^{(u)}\right)} \frac{n_{b, i}}{\log \left(1+n_{i}^{(u)}\right)}$

where $B(u)$ is the set of tags that user u has labeled, $B(i)$ is the set of tags that movie i is labeled, $n_{u, b}$ is the number of times that user u has labeled tag b, $n_{b, i}$ is the number of times that movie i has been labeled tag b, $n_b^{(u)}$ records how many different users have used tag b, $n_i^{(u)}$records how many different users have tagged the movie i. To get the specific value, we should build our function first.

&nbsp;

The difficulty of the function is to find the correct sets of tags or users. To acheive the goal, we use the knowledge we have learned in the class, manipulate the dataset count the corresponding numbers we need during each trail. Sum all of the value we got in each trail and then we can get the interest value of the user on specific movie (or item). The function code can be seen [here](https://shaocongz.github.io/Final_Project/tag_system_recommendation.html#Construct_interest_function).

&nbsp;

After building the function, we want to select the most popular movies to see how this function works. That is, we want to visualize the interest value. However, the dataset only contains about 3700 tags labeled by the users. The limited dataset will destroy the credibility of the tag-based recommendation system, as the user we want to analyze may have a few tags and there may also a few tags for movies. In order to making sure that the interest values to be nonzero, we will then choose several movies that have labeled most by users and select several active users. In this way, we select the users that have labeled more than 20 movies and select movies that has labeled by more than 4 users. The selected movies for example, Star Wars: Episode IV - A New Hope. The selected movies' table is [here](https://shaocongz.github.io/Final_Project/tag_system_recommendation.html#Find_the_most_popular_movies_and_the_most_active_users).

&nbsp;

To visualize the users' interest values, we decided to create a heat map. A heat map (or heatmap) is a data visualization technique that shows magnitude of a phenomenon as color in two dimensions. The variation in color may be by hue or intensity, giving obvious visual cues about how the phenomenon is clustered or varies over space. The heat map is shown below. The horizontal coordinate of the heat map is the movie ID and the vertical coordinate is the user ID, each corresponding color represents the level of the user's interest in the movie. The brighter the color (the greater the interest value), the deeper the interest, and the darker the color (the smaller the interest value), the lighter the interest. The detailed code is [here](https://shaocongz.github.io/Final_Project/tag_system_recommendation.html#Create_heat_map).

<img src="heat_map.PNG" style="width:75%">

&nbsp;

Tag based TF-IDF can help us predict the user's interest on a certain movie (or item). The algorithm's validity relies on a large dataset. That is, when enlarging the dataset, the system will become more and more accurate. In this way, the system works well for big websites due to their large user groups. 

&nbsp;

The algorithm above have punishment for popular tags and popular movies, and doesn't reduce the accuracy of the recommendation results while enhancing the personalization of the recommendation results.

&nbsp;

# Discussion

